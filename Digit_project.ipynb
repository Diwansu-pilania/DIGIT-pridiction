{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNOsBiX9aLXVrjad77a1FMP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Diwansu-pilania/DIGIT-pridiction/blob/main/Digit_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HANDWRITTEN DIGIT PROJECT"
      ],
      "metadata": {
        "id": "_1k3auUWkV5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##INSTALLING BASIC PYTORCH"
      ],
      "metadata": {
        "id": "yKhUpfpkkb_0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MkqjTE-VIsV",
        "outputId": "7413f19a-b8e5-4bd2-8979-94fb9183df3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Collecting torch\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nvjitlink-cu12-12.4.127 torch-2.6.0 torchvision-0.21.0 triton-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IMPORTOING LIBRARIES AND DATASETS"
      ],
      "metadata": {
        "id": "7VOkEY9Wkq4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "hGE9fP-aVgdd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##INITIALISING TEST AND TRAIN DATASET"
      ],
      "metadata": {
        "id": "XFoig3bykynM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    transform = ToTensor(),\n",
        "    download = True\n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    transform = ToTensor(),\n",
        "    download = True\n",
        ")"
      ],
      "metadata": {
        "id": "VeGJ8L4zXWE3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c42166-9535-4b0e-b0df-36d317de6339"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 30.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.67MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.2MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.23MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abtyde7YYEXs",
        "outputId": "8deaabc7-5429-4702-9e84-3b4fdfa758e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2tr83shYI18",
        "outputId": "46c5efbb-f84e-45b6-d295-b9cc38fba64c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8uglWtCYNXC",
        "outputId": "3ca5bbee-19e9-4358-f4b9-bab0e6efdf7e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--C8mNt5Yw8V",
        "outputId": "3872cce2-13c8-44f3-dd47-d74d6c4fe9ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###IMPORTING LOADERS"
      ],
      "metadata": {
        "id": "SQHynpjCk6Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "loaders = {\n",
        "    'train': DataLoader(train_data,\n",
        "                        batch_size=100,\n",
        "                        shuffle=True,\n",
        "                        num_workers=1),\n",
        "    'test': DataLoader(test_data,\n",
        "                        batch_size=100,\n",
        "                        shuffle=True,\n",
        "                        num_workers=1),\n",
        "}"
      ],
      "metadata": {
        "id": "7G2kQPYAY-vM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#INITIAALISING THE CNN"
      ],
      "metadata": {
        "id": "BCZXsbPVkOTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class CNN(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1 ,10, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "    self.conv2_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    x = x.view(-1, 320)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return F.softmax(x)"
      ],
      "metadata": {
        "id": "NAS1X0cObk-t"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EGeLqclCkS-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##INITIALISING HOW TO TRAIN EPOCH"
      ],
      "metadata": {
        "id": "porFeex4k_5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data,target) in enumerate(loaders['train']):\n",
        "    data,target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = loss_fn(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 20 ==0:\n",
        "      print(f'Train Epoch: {epoch} [{batch_idx*len(data)}/{len(loaders[\"train\"].dataset)} ({100.*batch_idx / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}')\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, target in loaders['test']:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        test_loss +=loss_fn(output,target).item()\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "\n",
        "  test_loss /= len(loaders['test'].dataset)\n",
        "  print(f'\\nTest set : average loss:{test_loss:4f}, Accuracy {correct}/{len(loaders[\"test\"].dataset)}({100.*correct / len(loaders[\"test\"].dataset):.0f}%\\n)')"
      ],
      "metadata": {
        "id": "VxrW8q5kmQ73"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TRAINING OF THE EPOCH"
      ],
      "metadata": {
        "id": "DcfHpw7NkFw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1,11):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "id": "E6EpQlhjraO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d25f11-6941-48d7-ce81-67a72c3f7aa4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-66d4a7f1c165>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\t2.302669\n",
            "Train Epoch: 1 [2000/60000 (3%)]\t2.283267\n",
            "Train Epoch: 1 [4000/60000 (7%)]\t2.260321\n",
            "Train Epoch: 1 [6000/60000 (10%)]\t2.107387\n",
            "Train Epoch: 1 [8000/60000 (13%)]\t1.933387\n",
            "Train Epoch: 1 [10000/60000 (17%)]\t1.949680\n",
            "Train Epoch: 1 [12000/60000 (20%)]\t1.885254\n",
            "Train Epoch: 1 [14000/60000 (23%)]\t1.849759\n",
            "Train Epoch: 1 [16000/60000 (27%)]\t1.839801\n",
            "Train Epoch: 1 [18000/60000 (30%)]\t1.848200\n",
            "Train Epoch: 1 [20000/60000 (33%)]\t1.847721\n",
            "Train Epoch: 1 [22000/60000 (37%)]\t1.745261\n",
            "Train Epoch: 1 [24000/60000 (40%)]\t1.761648\n",
            "Train Epoch: 1 [26000/60000 (43%)]\t1.777414\n",
            "Train Epoch: 1 [28000/60000 (47%)]\t1.726848\n",
            "Train Epoch: 1 [30000/60000 (50%)]\t1.710184\n",
            "Train Epoch: 1 [32000/60000 (53%)]\t1.655676\n",
            "Train Epoch: 1 [34000/60000 (57%)]\t1.626715\n",
            "Train Epoch: 1 [36000/60000 (60%)]\t1.655723\n",
            "Train Epoch: 1 [38000/60000 (63%)]\t1.614118\n",
            "Train Epoch: 1 [40000/60000 (67%)]\t1.640260\n",
            "Train Epoch: 1 [42000/60000 (70%)]\t1.608271\n",
            "Train Epoch: 1 [44000/60000 (73%)]\t1.553957\n",
            "Train Epoch: 1 [46000/60000 (77%)]\t1.595260\n",
            "Train Epoch: 1 [48000/60000 (80%)]\t1.630440\n",
            "Train Epoch: 1 [50000/60000 (83%)]\t1.641820\n",
            "Train Epoch: 1 [52000/60000 (87%)]\t1.690167\n",
            "Train Epoch: 1 [54000/60000 (90%)]\t1.614978\n",
            "Train Epoch: 1 [56000/60000 (93%)]\t1.656480\n",
            "Train Epoch: 1 [58000/60000 (97%)]\t1.566029\n",
            "\n",
            "Test set : average loss:0.015302, Accuracy 9339/10000(93%\n",
            ")\n",
            "Train Epoch: 2 [0/60000 (0%)]\t1.651005\n",
            "Train Epoch: 2 [2000/60000 (3%)]\t1.570273\n",
            "Train Epoch: 2 [4000/60000 (7%)]\t1.634855\n",
            "Train Epoch: 2 [6000/60000 (10%)]\t1.650075\n",
            "Train Epoch: 2 [8000/60000 (13%)]\t1.615691\n",
            "Train Epoch: 2 [10000/60000 (17%)]\t1.606841\n",
            "Train Epoch: 2 [12000/60000 (20%)]\t1.568774\n",
            "Train Epoch: 2 [14000/60000 (23%)]\t1.640179\n",
            "Train Epoch: 2 [16000/60000 (27%)]\t1.568244\n",
            "Train Epoch: 2 [18000/60000 (30%)]\t1.585194\n",
            "Train Epoch: 2 [20000/60000 (33%)]\t1.602862\n",
            "Train Epoch: 2 [22000/60000 (37%)]\t1.551058\n",
            "Train Epoch: 2 [24000/60000 (40%)]\t1.651415\n",
            "Train Epoch: 2 [26000/60000 (43%)]\t1.555085\n",
            "Train Epoch: 2 [28000/60000 (47%)]\t1.598528\n",
            "Train Epoch: 2 [30000/60000 (50%)]\t1.578463\n",
            "Train Epoch: 2 [32000/60000 (53%)]\t1.584619\n",
            "Train Epoch: 2 [34000/60000 (57%)]\t1.579746\n",
            "Train Epoch: 2 [36000/60000 (60%)]\t1.585469\n",
            "Train Epoch: 2 [38000/60000 (63%)]\t1.578240\n",
            "Train Epoch: 2 [40000/60000 (67%)]\t1.610934\n",
            "Train Epoch: 2 [42000/60000 (70%)]\t1.575502\n",
            "Train Epoch: 2 [44000/60000 (73%)]\t1.550680\n",
            "Train Epoch: 2 [46000/60000 (77%)]\t1.575210\n",
            "Train Epoch: 2 [48000/60000 (80%)]\t1.572928\n",
            "Train Epoch: 2 [50000/60000 (83%)]\t1.595367\n",
            "Train Epoch: 2 [52000/60000 (87%)]\t1.554715\n",
            "Train Epoch: 2 [54000/60000 (90%)]\t1.592262\n",
            "Train Epoch: 2 [56000/60000 (93%)]\t1.566655\n",
            "Train Epoch: 2 [58000/60000 (97%)]\t1.569900\n",
            "\n",
            "Test set : average loss:0.015140, Accuracy 9477/10000(95%\n",
            ")\n",
            "Train Epoch: 3 [0/60000 (0%)]\t1.555153\n",
            "Train Epoch: 3 [2000/60000 (3%)]\t1.576355\n",
            "Train Epoch: 3 [4000/60000 (7%)]\t1.554751\n",
            "Train Epoch: 3 [6000/60000 (10%)]\t1.589869\n",
            "Train Epoch: 3 [8000/60000 (13%)]\t1.589634\n",
            "Train Epoch: 3 [10000/60000 (17%)]\t1.572486\n",
            "Train Epoch: 3 [12000/60000 (20%)]\t1.542583\n",
            "Train Epoch: 3 [14000/60000 (23%)]\t1.575609\n",
            "Train Epoch: 3 [16000/60000 (27%)]\t1.564471\n",
            "Train Epoch: 3 [18000/60000 (30%)]\t1.611292\n",
            "Train Epoch: 3 [20000/60000 (33%)]\t1.512216\n",
            "Train Epoch: 3 [22000/60000 (37%)]\t1.607274\n",
            "Train Epoch: 3 [24000/60000 (40%)]\t1.517697\n",
            "Train Epoch: 3 [26000/60000 (43%)]\t1.633196\n",
            "Train Epoch: 3 [28000/60000 (47%)]\t1.542166\n",
            "Train Epoch: 3 [30000/60000 (50%)]\t1.579431\n",
            "Train Epoch: 3 [32000/60000 (53%)]\t1.611206\n",
            "Train Epoch: 3 [34000/60000 (57%)]\t1.558781\n",
            "Train Epoch: 3 [36000/60000 (60%)]\t1.585529\n",
            "Train Epoch: 3 [38000/60000 (63%)]\t1.593935\n",
            "Train Epoch: 3 [40000/60000 (67%)]\t1.645894\n",
            "Train Epoch: 3 [42000/60000 (70%)]\t1.567711\n",
            "Train Epoch: 3 [44000/60000 (73%)]\t1.571751\n",
            "Train Epoch: 3 [46000/60000 (77%)]\t1.510115\n",
            "Train Epoch: 3 [48000/60000 (80%)]\t1.583257\n",
            "Train Epoch: 3 [50000/60000 (83%)]\t1.544464\n",
            "Train Epoch: 3 [52000/60000 (87%)]\t1.518132\n",
            "Train Epoch: 3 [54000/60000 (90%)]\t1.551903\n",
            "Train Epoch: 3 [56000/60000 (93%)]\t1.529931\n",
            "Train Epoch: 3 [58000/60000 (97%)]\t1.556554\n",
            "\n",
            "Test set : average loss:0.015102, Accuracy 9498/10000(95%\n",
            ")\n",
            "Train Epoch: 4 [0/60000 (0%)]\t1.564861\n",
            "Train Epoch: 4 [2000/60000 (3%)]\t1.521381\n",
            "Train Epoch: 4 [4000/60000 (7%)]\t1.558808\n",
            "Train Epoch: 4 [6000/60000 (10%)]\t1.557152\n",
            "Train Epoch: 4 [8000/60000 (13%)]\t1.569579\n",
            "Train Epoch: 4 [10000/60000 (17%)]\t1.539997\n",
            "Train Epoch: 4 [12000/60000 (20%)]\t1.569487\n",
            "Train Epoch: 4 [14000/60000 (23%)]\t1.527169\n",
            "Train Epoch: 4 [16000/60000 (27%)]\t1.561165\n",
            "Train Epoch: 4 [18000/60000 (30%)]\t1.592448\n",
            "Train Epoch: 4 [20000/60000 (33%)]\t1.549280\n",
            "Train Epoch: 4 [22000/60000 (37%)]\t1.555652\n",
            "Train Epoch: 4 [24000/60000 (40%)]\t1.581201\n",
            "Train Epoch: 4 [26000/60000 (43%)]\t1.536125\n",
            "Train Epoch: 4 [28000/60000 (47%)]\t1.589798\n",
            "Train Epoch: 4 [30000/60000 (50%)]\t1.567380\n",
            "Train Epoch: 4 [32000/60000 (53%)]\t1.544557\n",
            "Train Epoch: 4 [34000/60000 (57%)]\t1.551920\n",
            "Train Epoch: 4 [36000/60000 (60%)]\t1.599037\n",
            "Train Epoch: 4 [38000/60000 (63%)]\t1.522774\n",
            "Train Epoch: 4 [40000/60000 (67%)]\t1.574678\n",
            "Train Epoch: 4 [42000/60000 (70%)]\t1.612098\n",
            "Train Epoch: 4 [44000/60000 (73%)]\t1.572050\n",
            "Train Epoch: 4 [46000/60000 (77%)]\t1.642111\n",
            "Train Epoch: 4 [48000/60000 (80%)]\t1.540611\n",
            "Train Epoch: 4 [50000/60000 (83%)]\t1.654185\n",
            "Train Epoch: 4 [52000/60000 (87%)]\t1.559040\n",
            "Train Epoch: 4 [54000/60000 (90%)]\t1.572270\n",
            "Train Epoch: 4 [56000/60000 (93%)]\t1.533338\n",
            "Train Epoch: 4 [58000/60000 (97%)]\t1.542038\n",
            "\n",
            "Test set : average loss:0.015018, Accuracy 9594/10000(96%\n",
            ")\n",
            "Train Epoch: 5 [0/60000 (0%)]\t1.534405\n",
            "Train Epoch: 5 [2000/60000 (3%)]\t1.527849\n",
            "Train Epoch: 5 [4000/60000 (7%)]\t1.563708\n",
            "Train Epoch: 5 [6000/60000 (10%)]\t1.504387\n",
            "Train Epoch: 5 [8000/60000 (13%)]\t1.543807\n",
            "Train Epoch: 5 [10000/60000 (17%)]\t1.537364\n",
            "Train Epoch: 5 [12000/60000 (20%)]\t1.529232\n",
            "Train Epoch: 5 [14000/60000 (23%)]\t1.517387\n",
            "Train Epoch: 5 [16000/60000 (27%)]\t1.560728\n",
            "Train Epoch: 5 [18000/60000 (30%)]\t1.525562\n",
            "Train Epoch: 5 [20000/60000 (33%)]\t1.556737\n",
            "Train Epoch: 5 [22000/60000 (37%)]\t1.584078\n",
            "Train Epoch: 5 [24000/60000 (40%)]\t1.563348\n",
            "Train Epoch: 5 [26000/60000 (43%)]\t1.579011\n",
            "Train Epoch: 5 [28000/60000 (47%)]\t1.563853\n",
            "Train Epoch: 5 [30000/60000 (50%)]\t1.552223\n",
            "Train Epoch: 5 [32000/60000 (53%)]\t1.550363\n",
            "Train Epoch: 5 [34000/60000 (57%)]\t1.577463\n",
            "Train Epoch: 5 [36000/60000 (60%)]\t1.595315\n",
            "Train Epoch: 5 [38000/60000 (63%)]\t1.545256\n",
            "Train Epoch: 5 [40000/60000 (67%)]\t1.577886\n",
            "Train Epoch: 5 [42000/60000 (70%)]\t1.535676\n",
            "Train Epoch: 5 [44000/60000 (73%)]\t1.558642\n",
            "Train Epoch: 5 [46000/60000 (77%)]\t1.534364\n",
            "Train Epoch: 5 [48000/60000 (80%)]\t1.567244\n",
            "Train Epoch: 5 [50000/60000 (83%)]\t1.532762\n",
            "Train Epoch: 5 [52000/60000 (87%)]\t1.530603\n",
            "Train Epoch: 5 [54000/60000 (90%)]\t1.544404\n",
            "Train Epoch: 5 [56000/60000 (93%)]\t1.506408\n",
            "Train Epoch: 5 [58000/60000 (97%)]\t1.597871\n",
            "\n",
            "Test set : average loss:0.014954, Accuracy 9655/10000(97%\n",
            ")\n",
            "Train Epoch: 6 [0/60000 (0%)]\t1.541079\n",
            "Train Epoch: 6 [2000/60000 (3%)]\t1.515163\n",
            "Train Epoch: 6 [4000/60000 (7%)]\t1.520092\n",
            "Train Epoch: 6 [6000/60000 (10%)]\t1.544852\n",
            "Train Epoch: 6 [8000/60000 (13%)]\t1.510081\n",
            "Train Epoch: 6 [10000/60000 (17%)]\t1.561999\n",
            "Train Epoch: 6 [12000/60000 (20%)]\t1.509924\n",
            "Train Epoch: 6 [14000/60000 (23%)]\t1.542134\n",
            "Train Epoch: 6 [16000/60000 (27%)]\t1.580809\n",
            "Train Epoch: 6 [18000/60000 (30%)]\t1.545176\n",
            "Train Epoch: 6 [20000/60000 (33%)]\t1.542409\n",
            "Train Epoch: 6 [22000/60000 (37%)]\t1.521177\n",
            "Train Epoch: 6 [24000/60000 (40%)]\t1.569846\n",
            "Train Epoch: 6 [26000/60000 (43%)]\t1.558248\n",
            "Train Epoch: 6 [28000/60000 (47%)]\t1.532760\n",
            "Train Epoch: 6 [30000/60000 (50%)]\t1.544812\n",
            "Train Epoch: 6 [32000/60000 (53%)]\t1.541151\n",
            "Train Epoch: 6 [34000/60000 (57%)]\t1.535090\n",
            "Train Epoch: 6 [36000/60000 (60%)]\t1.582224\n",
            "Train Epoch: 6 [38000/60000 (63%)]\t1.522637\n",
            "Train Epoch: 6 [40000/60000 (67%)]\t1.541452\n",
            "Train Epoch: 6 [42000/60000 (70%)]\t1.549738\n",
            "Train Epoch: 6 [44000/60000 (73%)]\t1.536417\n",
            "Train Epoch: 6 [46000/60000 (77%)]\t1.546377\n",
            "Train Epoch: 6 [48000/60000 (80%)]\t1.528846\n",
            "Train Epoch: 6 [50000/60000 (83%)]\t1.533359\n",
            "Train Epoch: 6 [52000/60000 (87%)]\t1.600336\n",
            "Train Epoch: 6 [54000/60000 (90%)]\t1.478757\n",
            "Train Epoch: 6 [56000/60000 (93%)]\t1.528021\n",
            "Train Epoch: 6 [58000/60000 (97%)]\t1.525118\n",
            "\n",
            "Test set : average loss:0.014950, Accuracy 9665/10000(97%\n",
            ")\n",
            "Train Epoch: 7 [0/60000 (0%)]\t1.542967\n",
            "Train Epoch: 7 [2000/60000 (3%)]\t1.556660\n",
            "Train Epoch: 7 [4000/60000 (7%)]\t1.548133\n",
            "Train Epoch: 7 [6000/60000 (10%)]\t1.557458\n",
            "Train Epoch: 7 [8000/60000 (13%)]\t1.515499\n",
            "Train Epoch: 7 [10000/60000 (17%)]\t1.534177\n",
            "Train Epoch: 7 [12000/60000 (20%)]\t1.575245\n",
            "Train Epoch: 7 [14000/60000 (23%)]\t1.537632\n",
            "Train Epoch: 7 [16000/60000 (27%)]\t1.530088\n",
            "Train Epoch: 7 [18000/60000 (30%)]\t1.580774\n",
            "Train Epoch: 7 [20000/60000 (33%)]\t1.540140\n",
            "Train Epoch: 7 [22000/60000 (37%)]\t1.560826\n",
            "Train Epoch: 7 [24000/60000 (40%)]\t1.552151\n",
            "Train Epoch: 7 [26000/60000 (43%)]\t1.576976\n",
            "Train Epoch: 7 [28000/60000 (47%)]\t1.531046\n",
            "Train Epoch: 7 [30000/60000 (50%)]\t1.553054\n",
            "Train Epoch: 7 [32000/60000 (53%)]\t1.543292\n",
            "Train Epoch: 7 [34000/60000 (57%)]\t1.540451\n",
            "Train Epoch: 7 [36000/60000 (60%)]\t1.531884\n",
            "Train Epoch: 7 [38000/60000 (63%)]\t1.538578\n",
            "Train Epoch: 7 [40000/60000 (67%)]\t1.521902\n",
            "Train Epoch: 7 [42000/60000 (70%)]\t1.534010\n",
            "Train Epoch: 7 [44000/60000 (73%)]\t1.601047\n",
            "Train Epoch: 7 [46000/60000 (77%)]\t1.490410\n",
            "Train Epoch: 7 [48000/60000 (80%)]\t1.510713\n",
            "Train Epoch: 7 [50000/60000 (83%)]\t1.523565\n",
            "Train Epoch: 7 [52000/60000 (87%)]\t1.542439\n",
            "Train Epoch: 7 [54000/60000 (90%)]\t1.525798\n",
            "Train Epoch: 7 [56000/60000 (93%)]\t1.516341\n",
            "Train Epoch: 7 [58000/60000 (97%)]\t1.549308\n",
            "\n",
            "Test set : average loss:0.014932, Accuracy 9688/10000(97%\n",
            ")\n",
            "Train Epoch: 8 [0/60000 (0%)]\t1.512627\n",
            "Train Epoch: 8 [2000/60000 (3%)]\t1.536220\n",
            "Train Epoch: 8 [4000/60000 (7%)]\t1.528217\n",
            "Train Epoch: 8 [6000/60000 (10%)]\t1.507021\n",
            "Train Epoch: 8 [8000/60000 (13%)]\t1.492162\n",
            "Train Epoch: 8 [10000/60000 (17%)]\t1.585744\n",
            "Train Epoch: 8 [12000/60000 (20%)]\t1.527500\n",
            "Train Epoch: 8 [14000/60000 (23%)]\t1.533538\n",
            "Train Epoch: 8 [16000/60000 (27%)]\t1.529227\n",
            "Train Epoch: 8 [18000/60000 (30%)]\t1.550519\n",
            "Train Epoch: 8 [20000/60000 (33%)]\t1.559353\n",
            "Train Epoch: 8 [22000/60000 (37%)]\t1.529741\n",
            "Train Epoch: 8 [24000/60000 (40%)]\t1.525539\n",
            "Train Epoch: 8 [26000/60000 (43%)]\t1.552697\n",
            "Train Epoch: 8 [28000/60000 (47%)]\t1.549418\n",
            "Train Epoch: 8 [30000/60000 (50%)]\t1.530403\n",
            "Train Epoch: 8 [32000/60000 (53%)]\t1.532374\n",
            "Train Epoch: 8 [34000/60000 (57%)]\t1.568561\n",
            "Train Epoch: 8 [36000/60000 (60%)]\t1.579133\n",
            "Train Epoch: 8 [38000/60000 (63%)]\t1.540915\n",
            "Train Epoch: 8 [40000/60000 (67%)]\t1.572365\n",
            "Train Epoch: 8 [42000/60000 (70%)]\t1.586251\n",
            "Train Epoch: 8 [44000/60000 (73%)]\t1.504124\n",
            "Train Epoch: 8 [46000/60000 (77%)]\t1.520719\n",
            "Train Epoch: 8 [48000/60000 (80%)]\t1.560823\n",
            "Train Epoch: 8 [50000/60000 (83%)]\t1.545654\n",
            "Train Epoch: 8 [52000/60000 (87%)]\t1.552241\n",
            "Train Epoch: 8 [54000/60000 (90%)]\t1.566382\n",
            "Train Epoch: 8 [56000/60000 (93%)]\t1.579739\n",
            "Train Epoch: 8 [58000/60000 (97%)]\t1.515860\n",
            "\n",
            "Test set : average loss:0.014926, Accuracy 9683/10000(97%\n",
            ")\n",
            "Train Epoch: 9 [0/60000 (0%)]\t1.527773\n",
            "Train Epoch: 9 [2000/60000 (3%)]\t1.523986\n",
            "Train Epoch: 9 [4000/60000 (7%)]\t1.511482\n",
            "Train Epoch: 9 [6000/60000 (10%)]\t1.540905\n",
            "Train Epoch: 9 [8000/60000 (13%)]\t1.540849\n",
            "Train Epoch: 9 [10000/60000 (17%)]\t1.552195\n",
            "Train Epoch: 9 [12000/60000 (20%)]\t1.539443\n",
            "Train Epoch: 9 [14000/60000 (23%)]\t1.525076\n",
            "Train Epoch: 9 [16000/60000 (27%)]\t1.504974\n",
            "Train Epoch: 9 [18000/60000 (30%)]\t1.547026\n",
            "Train Epoch: 9 [20000/60000 (33%)]\t1.523852\n",
            "Train Epoch: 9 [22000/60000 (37%)]\t1.550128\n",
            "Train Epoch: 9 [24000/60000 (40%)]\t1.501203\n",
            "Train Epoch: 9 [26000/60000 (43%)]\t1.494707\n",
            "Train Epoch: 9 [28000/60000 (47%)]\t1.548372\n",
            "Train Epoch: 9 [30000/60000 (50%)]\t1.514378\n",
            "Train Epoch: 9 [32000/60000 (53%)]\t1.503469\n",
            "Train Epoch: 9 [34000/60000 (57%)]\t1.524241\n",
            "Train Epoch: 9 [36000/60000 (60%)]\t1.557834\n",
            "Train Epoch: 9 [38000/60000 (63%)]\t1.523463\n",
            "Train Epoch: 9 [40000/60000 (67%)]\t1.491768\n",
            "Train Epoch: 9 [42000/60000 (70%)]\t1.538769\n",
            "Train Epoch: 9 [44000/60000 (73%)]\t1.553853\n",
            "Train Epoch: 9 [46000/60000 (77%)]\t1.566479\n",
            "Train Epoch: 9 [48000/60000 (80%)]\t1.546526\n",
            "Train Epoch: 9 [50000/60000 (83%)]\t1.487769\n",
            "Train Epoch: 9 [52000/60000 (87%)]\t1.614508\n",
            "Train Epoch: 9 [54000/60000 (90%)]\t1.535782\n",
            "Train Epoch: 9 [56000/60000 (93%)]\t1.549490\n",
            "Train Epoch: 9 [58000/60000 (97%)]\t1.540003\n",
            "\n",
            "Test set : average loss:0.014902, Accuracy 9704/10000(97%\n",
            ")\n",
            "Train Epoch: 10 [0/60000 (0%)]\t1.530143\n",
            "Train Epoch: 10 [2000/60000 (3%)]\t1.543137\n",
            "Train Epoch: 10 [4000/60000 (7%)]\t1.541922\n",
            "Train Epoch: 10 [6000/60000 (10%)]\t1.569442\n",
            "Train Epoch: 10 [8000/60000 (13%)]\t1.557680\n",
            "Train Epoch: 10 [10000/60000 (17%)]\t1.521692\n",
            "Train Epoch: 10 [12000/60000 (20%)]\t1.521830\n",
            "Train Epoch: 10 [14000/60000 (23%)]\t1.551248\n",
            "Train Epoch: 10 [16000/60000 (27%)]\t1.510535\n",
            "Train Epoch: 10 [18000/60000 (30%)]\t1.506860\n",
            "Train Epoch: 10 [20000/60000 (33%)]\t1.577659\n",
            "Train Epoch: 10 [22000/60000 (37%)]\t1.525462\n",
            "Train Epoch: 10 [24000/60000 (40%)]\t1.532047\n",
            "Train Epoch: 10 [26000/60000 (43%)]\t1.511926\n",
            "Train Epoch: 10 [28000/60000 (47%)]\t1.512862\n",
            "Train Epoch: 10 [30000/60000 (50%)]\t1.517341\n",
            "Train Epoch: 10 [32000/60000 (53%)]\t1.534983\n",
            "Train Epoch: 10 [34000/60000 (57%)]\t1.498318\n",
            "Train Epoch: 10 [36000/60000 (60%)]\t1.524505\n",
            "Train Epoch: 10 [38000/60000 (63%)]\t1.513510\n",
            "Train Epoch: 10 [40000/60000 (67%)]\t1.523986\n",
            "Train Epoch: 10 [42000/60000 (70%)]\t1.510426\n",
            "Train Epoch: 10 [44000/60000 (73%)]\t1.535735\n",
            "Train Epoch: 10 [46000/60000 (77%)]\t1.521850\n",
            "Train Epoch: 10 [48000/60000 (80%)]\t1.533997\n",
            "Train Epoch: 10 [50000/60000 (83%)]\t1.515046\n",
            "Train Epoch: 10 [52000/60000 (87%)]\t1.506490\n",
            "Train Epoch: 10 [54000/60000 (90%)]\t1.548902\n",
            "Train Epoch: 10 [56000/60000 (93%)]\t1.526995\n",
            "Train Epoch: 10 [58000/60000 (97%)]\t1.504307\n",
            "\n",
            "Test set : average loss:0.014914, Accuracy 9700/10000(97%\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66e9i0Tg0Mri",
        "outputId": "c7a05645-b1a5-4328-925a-4f45567b9c44"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PREDICTION OF TEST DATA"
      ],
      "metadata": {
        "id": "9NmG_UYQj0zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "\n",
        "data, target = test_data[9]\n",
        "\n",
        "data = data.unsqueeze(0).to(device)\n",
        "\n",
        "output = model(data)\n",
        "\n",
        "prediction = output.argmax(dim=1,keepdim=True).item()\n",
        "\n",
        "print(f'PREDICTION: {prediction}')\n",
        "\n",
        "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
        "\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "Fz7rlYJh5Tca",
        "outputId": "a36f75f9-fc4b-4b76-a6ed-ac7b8ad66f61"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PREDICTION: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-66d4a7f1c165>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PREDICTION OF ANY HANDWRITTEN DIGIT"
      ],
      "metadata": {
        "id": "2PlmTVtOj8uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "def load_image(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((28, 28)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "    image = Image.open(image_path).convert('L')\n",
        "    image = transform(image).unsqueeze(0)\n",
        "    return image\n",
        "\n",
        "image_path = '/content/THREE.jpg'\n",
        "image_tensor = load_image(image_path)"
      ],
      "metadata": {
        "id": "51vFmWsn6nd7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(image_tensor.to(device))\n",
        "    prediction = output.argmax(dim=1, keepdim=True).item()\n",
        "\n",
        "print(f'Prediction: {prediction}')\n",
        "\n",
        "image = image_tensor.squeeze(0).squeeze(0).cpu().numpy()\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(f'Predicted Digit: {prediction}')\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "_tS4XHMIhg40",
        "outputId": "b69fada4-e2fe-4acc-b171-9b37e7686014"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-66d4a7f1c165>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QZ1yzZ03hvbi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}